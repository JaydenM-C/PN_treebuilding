}
sig
}
two_tailed_Pval1 <- function(Pval_1, alpha = 0.05) {
if (Pval_1 > (1 - alpha / 2)) {
sig <- "more dispersed than random expectation"
} else if (Pval_1 < (alpha / 2)) {
sig <- "more clumped than random expectation"
} else {
sig <- "consistent with random expectation"
}
}
d_test_table$Pval0_sig <- sapply(d_test_table$biphone, function(x) two_tailed_Pval0(d_test_table[d_test_table$biphone == x, "Pval_0"], alpha = 0.025))
d_test_table$Pval1_sig <- sapply(d_test_table$biphone, function(x) two_tailed_Pval1(d_test_table[d_test_table$biphone == x, "Pval_1"], alpha = 0.025))
describe_significance <- function (Pval0_sig, Pval1_sig) {
if (Pval0_sig == "more clumped than Brownian expectation" &
Pval1_sig == "more clumped than random expectation") {
sig <- "More clumped"
} else if (Pval0_sig == "more dispersed than Brownian expectation" &
Pval1_sig == "more dispersed than random expectation") {
sig <- "More dispersed"
} else if (Pval0_sig == "consistent with Brownian expectation" &
Pval1_sig == "more clumped than random expectation") {
sig <- "Phylogenetic"
} else if (Pval0_sig == "more dispersed than Brownian expectation" &
Pval1_sig == "consistent with random expectation") {
sig <- "Random"
} else if (Pval0_sig == "more dispersed than Brownian expectation" &
Pval1_sig == "more clumped than random expectation") {
sig <- "0 < D < 1 (both H0s rejected)"
} else if (Pval0_sig == "consistent with Brownian expectation" &
Pval1_sig == "consistent with random expectation") {
sig <- "Indeterminate (neither H0 rejected)"
}
}
d_test_table$result <- sapply(d_test_table$biphone, function(x) describe_significance(d_test_table[d_test_table$biphone == x, "Pval0_sig"], d_test_table[d_test_table$biphone == x, "Pval1_sig"]))
d_test_table$Pval0_sig <- as.factor(d_test_table$Pval0_sig)
d_test_table$Pval1_sig <- as.factor(d_test_table$Pval1_sig)
d_test_table$result    <- as.factor(d_test_table$result)
write_csv(d_test_table, paste0("../results/D_test_results_", Sys.Date(), ".csv"))
# To get some summary statistics, run the following:
# summary(d_test_table)
# d_test_table <- read_csv("../results/D_test_results_2020-08-07.csv")
# Five moments of the distribution of D test values
# moments <- function(dat) {
#   cat(paste0(
#     "Mean: ", mean(dat), "\n",
#     "Std dev: ", sd(dat), "\n",
#     "Median: ", median(dat), "\n",
#     "Skewness: ", skewness(dat), "\n",
#     "Kurtosis: ", kurtosis(dat), "\n"
#   )
#   )
# }
#
# moments(d_test_table$D)
##############################
# K TEST WITH BIPHONES
##############################
# Create data frame with rownames, as required by multiPhylosignal
create_char_df <- function(dat) {
df <- as.data.frame(dat)
rownames(df) <- df$tip_label
df[, "tip_label"] <- NULL
df
}
# Extra functions for tabulating results
one_tailed_p <- function (p, alpha = 0.05) {
if (p < alpha) {
sig <- "yes"
} else {
sig <- "no"
}
sig
}
extra_K_analysis <- function(results, dataset) {
results$significant <- sapply(results$PIC.variance.P, function(x) as.factor(one_tailed_p(x)))
results$biphone <- rownames(results)
results$n_langs <- sapply(results$biphone, function(x) sum(!is.na(dataset[,x])))
results
}
# Run test
# (run time: ~30 min on 8GB Macbook Pro)
K_biphones_fwd_results  <- K_biphones_fwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_biphones_fwd)
K_biphones_bkwd_results <- K_biphones_bkwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_biphones_bkwd)
write_csv(K_biphones_fwd_results, paste0("../results/K_biphones_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_biphones_bkwd_results, paste0("../results/K_biphones_bkwd_results_", Sys.Date(), ".csv"))
# To inspect results, run the following:
# K_biphones_fwd_results <- read_csv("../results/K_biphones_fwd_results_2020-08-07.csv")
# K_biphones_fwd_results$significant <- as.factor(K_biphones_fwd_results$significant)
# K_biphones_bkwd_results <- read_csv("../results/K_biphones_bkwd_results_2020-08-07.csv")
# K_biphones_bkwd_results$significant <- as.factor(K_biphones_bkwd_results$significant)
# There is no statistically significant difference between K tests for
# forward transition frequences and backward transition frequencies:
# fwd <- dplyr::select(K_biphones_fwd_results, K)
# bkwd <- dplyr::select(K_biphones_bkwd_results, K)
# t.test(fwd$K, bkwd$K)
# ks.test(fwd$K, bkwd$K)
# Plot the distribution of values for every character in the dataset.
# This produces a large sheet of density plots, one for each character:
# library(purrr)
#
# biphones_fwd %>%
#   keep(is.numeric) %>%
#   gather() %>%
#   ggplot(aes(value)) +
#   facet_wrap(~ key, scales = "free") +
#   geom_density(fill = "grey") +
#   theme_classic()
#
# biphones_bkwd %>%
#   keep(is.numeric) %>%
#   gather() %>%
#   ggplot(aes(value)) +
#   facet_wrap(~ key, scales = "free") +
#   geom_density(fill = "grey") +
#   theme_classic()
# Plot the same as above, but with normalised character values:
# library(purrr)
#
# biphones_fwd_norm %>%
#   keep(is.numeric) %>%
#   gather() %>%
#   ggplot(aes(value)) +
#   facet_wrap(~ key, scales = "free") +
#   geom_density(fill = "grey") +
#   theme_classic()
#
# biphones_bkwd_norm %>%
#   keep(is.numeric) %>%
#   gather() %>%
#   ggplot(aes(value)) +
#   facet_wrap(~ key, scales = "free") +
#   geom_density(fill = "grey") +
#   theme_classic()
# Rerunning the same $K$ analysis as before, but with normalized character values:
K_biphones_fwd_norm_results <- K_biphones_fwd %>%
create_char_df %>%
apply(2, function(x) transformTukey(x, plotit = FALSE)) %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_biphones_fwd)
K_biphones_bkwd_norm_results <- K_biphones_bkwd %>%
create_char_df %>%
apply(2, function(x) transformTukey(x, plotit = FALSE)) %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_biphones_bkwd)
write_csv(K_biphones_fwd_norm_results, paste0("../results/K_biphones_fwd_norm_results_", Sys.Date(), ".csv"))
write_csv(K_biphones_bkwd_norm_results, paste0("../results/K_biphones_bkwd_norm_results_", Sys.Date(), ".csv"))
# To inspect results, run the following:
# K_biphones_fwd_norm_results <- read_csv("../results/K_biphones_fwd_norm_results_2020-08-07.csv")
# K_biphones_fwd_norm_results$significant <- as.factor(K_biphones_fwd_norm_results$significant)
# K_biphones_bkwd_norm_results <- read_csv("../results/K_biphones_bkwd_norm_results_2020-08-07.csv")
# K_biphones_bkwd_norm_results$significant <- as.factor(K_biphones_bkwd_norm_results$significant)
# Compare K analyses with untransformed character values versus normalised values:
# raw <- bind_rows(K_biphones_fwd_results, K_biphones_bkwd_results) %>%
# dplyr::select(K)
# norm <- bind_rows(K_biphones_fwd_norm_results, K_biphones_bkwd_norm_results) %>%
#   dplyr::select(K)
# There is no statistically significant difference between means of $K$:
# t.test(raw$K, norm$K)
# ks.test(raw$K, norm$K)
##############################
# K TEST WITH NATURAL CLASSES
##############################
# Run test
K_place_fwd_results <- K_place_fwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_place_fwd)
K_place_bkwd_results <- K_place_bkwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_place_bkwd)
K_major_place_fwd_results <- K_major_place_fwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_major_place_fwd)
K_major_place_bkwd_results <- K_major_place_bkwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_major_place_bkwd)
K_manner_fwd_results <- K_manner_fwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_manner_fwd)
K_manner_bkwd_results <- K_manner_bkwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_manner_bkwd)
write_csv(K_place_fwd_results, paste0("../results/K_place_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_place_bkwd_results, paste0("../results/K_place_bkwd_results_", Sys.Date(), ".csv"))
write_csv(K_major_place_fwd_results, paste0("../results/K_major_place_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_major_place_bkwd_results, paste0("../results/K_major_place_bkwd_results_", Sys.Date(), ".csv"))
write_csv(K_manner_fwd_results, paste0("../results/K_manner_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_manner_bkwd_results, paste0("../results/K_manner_bkwd_results_", Sys.Date(), ".csv"))
# To inspect results, run the following:
# K_place_fwd_results        <- read_csv("../results/K_place_fwd_results_2020-08-07.csv")
# K_place_bkwd_results       <- read_csv("../results/K_place_bkwd_results_2020-08-07.csv")
# K_major_place_fwd_results  <- read_csv("../results/K_major_place_fwd_results_2020-08-07.csv")
# K_major_place_bkwd_results <- read_csv("../results/K_major_place_bkwd_results_2020-08-07.csv")
# K_manner_fwd_results       <- read_csv("../results/K_manner_fwd_results_2020-08-07.csv")
# K_manner_bkwd_results      <- read_csv("../results/K_manner_bkwd_results_2020-08-07.csv")
# Compare all natural class types:
# all_features <- bind_rows(K_place_fwd_results, K_place_bkwd_results,
#                           K_major_place_fwd_results, K_major_place_bkwd_results,
#                           K_manner_fwd_results, K_manner_bkwd_results)
# all_features$significant <- as.factor(all_features$significant)
#
# summary(all_features)
# Compare K for biphone characters versus natural class-based characters:
# all_biphones <- bind_rows(K_biphones_fwd_results, K_biphones_bkwd_results) %>%
#   dplyr::select(K)
# all_features <- dplyr::select(all_features, K)
# Forward and backward transition probabilities for transitions between natural classes show a greater degree of phylogenetic signal than biphone-based characters:
# t.test(all_biphones$K, all_features$K)
# ks.test(all_biphones$K, all_features$K)
# Compare K for different natural class types:
# all_place <- bind_rows(K_place_fwd_results, K_place_bkwd_results) %>%
#   dplyr::select(K)
# all_place$class_type <- "Place features"
# all_major_place <- bind_rows(K_major_place_fwd_results, K_major_place_bkwd_results) %>%
#   dplyr::select(K)
# all_major_place$class_type <- "Major place features"
# all_manner <- bind_rows(K_manner_fwd_results, K_manner_bkwd_results) %>%
#   dplyr::select(K)
# all_manner$class_type <- "Manner features"
# The difference in means between the three different kinds of natural classes is not significant according to a one-way ANOVA:
# k_all_classes <- bind_rows(all_place, all_major_place, all_manner)
#
# fit = lm(K ~ class_type, k_all_classes)
# anova(fit)
# ad.test(K ~ class_type, data = k_all_classes)
##############################
# BROWNIAN MOTION SIMULATION
##############################
# Simulation of Brownian motion on the Pama-Nyungan phylogeny with various levels of noise
# PN_SDollo_sum_4 <- as(PN_SDollo_sum, "phylo4")
# sim <- phyloSim(PN_SDollo_sum_4, methods = "K", nsim = 100, reps = 100, pb = FALSE)
# Inspect results:
# plot(sim, quantiles = c(0.05, 0.95))
# plot(sim, what = "pval")
setwd("~/Desktop/Github/phylo-sig-new/R")
##############################
# SET UP
##############################
# Load packages
library(tidyverse)
library(ape)
library(picante)
# Set seed for reproducibility of stochastic processes
set.seed(2019)
######################################
# K TEST WITH MIDDLE 50% OF WORDLISTS
######################################
# Get wordlist sizes
lex_sizes <- read_csv("../data/wordlist_sizes_2020-08-07.csv")
lex_IQR <- filter(lex_sizes, between(lex_sizes$n_entries, quantile(lex_sizes$n_entries)[2], quantile(lex_sizes$n_entries)[4]))
# Read reference tree
PN_SDollo_sum <- read.nexus("../trees/PNY10_285.(time).sum.tree")
### PREPARE DATA ###
# Function to filter out characters with too many missing values
# The rm_0 parameter optionally converts 0 values to NAs (important for K test)
filter_phylo_data <- function(dataset, lim = 50, rm_0 = FALSE) {
if (rm_0 == TRUE) {
dataset[dataset == 0] <- NA
}
df <- select_if(dataset, ~sum(!is.na(.)) >= lim)
df
}
# Function to drop uninformative variables (where all values are the same)
drop_uninformative_vars <- function(dataset) {
uniquelength <- sapply(dataset, function(x) length(unique(x[!is.na(x)])))
df <- subset(dataset, select = uniquelength > 1)
df
}
# Prepare sound class frequency data (min 20 non-NA values)
K_place_fwd <- read_csv("../data/place_fwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_IQR$tip_label)
K_place_bkwd <- read_csv("../data/place_bkwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_IQR$tip_label)
K_manner_fwd <- read_csv("../data/manner_fwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_IQR$tip_label)
K_manner_bkwd <- read_csv("../data/manner_bkwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_IQR$tip_label)
### ANALYSIS ###
# Create data frame with rownames, as required by multiPhylosignal
create_char_df <- function(dat) {
df <- as.data.frame(dat)
rownames(df) <- df$tip_label
df[, "tip_label"] <- NULL
df
}
# Extra functions for tabulating results
one_tailed_p <- function (p, alpha = 0.05) {
if (p < alpha) {
sig <- "yes"
} else {
sig <- "no"
}
sig
}
extra_K_analysis <- function(results, dataset) {
results$significant <- sapply(results$PIC.variance.P, function(x) as.factor(one_tailed_p(x)))
results$biphone <- rownames(results)
results$n_langs <- sapply(results$biphone, function(x) sum(!is.na(dataset[,x])))
results
}
# Run test
K_place_fwd_results <- K_place_fwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_place_fwd)
K_place_bkwd_results <- K_place_bkwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_place_bkwd)
K_manner_fwd_results <- K_manner_fwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_manner_fwd)
K_manner_bkwd_results <- K_manner_bkwd %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_manner_bkwd)
write_csv(K_place_fwd_results, paste0("../results/IQR_K_place_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_place_bkwd_results, paste0("../results/IQR_K_place_bkwd_results_", Sys.Date(), ".csv"))
write_csv(K_manner_fwd_results, paste0("../results/IQR_K_manner_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_manner_bkwd_results, paste0("../results/IQR_K_manner_bkwd_results_", Sys.Date(), ".csv"))
#################################
# K TEST WITH EVERY 2ND WORDLIST
#################################
lex_every2nd <-  arrange(lex_sizes, n_entries)[seq(2,111, by = 2),]
# Prepare sound class frequency data (min 20 non-NA values)
K_place_fwd_2        <- read_csv("../data/place_fwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_every2nd$tip_label)
K_place_bkwd_2       <- read_csv("../data/place_bkwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_every2nd$tip_label)
K_manner_fwd_2       <- read_csv("../data/manner_fwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_every2nd$tip_label)
K_manner_bkwd_2      <- read_csv("../data/manner_bkwd_2020-08-07.csv") %>%
filter_phylo_data(lim = 20, rm_0 = TRUE) %>%
drop_uninformative_vars() %>%
filter(tip_label %in% lex_every2nd$tip_label)
# Run test
K_place_fwd_2_results <- K_place_fwd_2 %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_place_fwd_2)
K_place_bkwd_2_results <- K_place_bkwd_2 %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_place_bkwd_2)
K_manner_fwd_2_results <- K_manner_fwd_2 %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_manner_fwd_2)
K_manner_bkwd_2_results <- K_manner_bkwd_2 %>%
create_char_df %>%
multiPhylosignal(PN_SDollo_sum, reps = 10000) %>%
extra_K_analysis(K_manner_bkwd_2)
write_csv(K_place_fwd_2_results, paste0("../results/Every2nd_K_place_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_place_bkwd_2_results, paste0("../results/Every2nd_K_place_bkwd_results_", Sys.Date(), ".csv"))
write_csv(K_manner_fwd_2_results, paste0("../results/Every2nd_K_manner_fwd_results_", Sys.Date(), ".csv"))
write_csv(K_manner_bkwd_2_results, paste0("../results/Every2nd_K_manner_bkwd_results_", Sys.Date(), ".csv"))
# For BBA 2018
library(tidyverse)
library(Ausphonlex)
lgs <- read_tsv("pny10_285_full.tab")
setwd("~/Downloads")
lgs <- read_tsv("pny10_285_full.tab")
View(lgs)
lgs <- read_tsv("pny10_285_full.tab", col_names = FALSE)
subgroups <- unique(unlist(lgs$X3))
setwd("~/Downloads")
cogs <- read_tsv("pny10_285_full.tab", col_names = FALSE)
setwd("~/Desktop/Github/phylo-sig-new/data")
lgs <- read_csv("wordlist_sizes_2020-06-05.csv")
subgroups <- unique(unlist(cogs$X3))
get_subgroup <- function (lg) {
df <- filter(cogs, X4 = lg)
unique(df$X3)
}
get_subgroup("Warlpiri")
df <- filter(cogs, X4 == lg)
get_subgroup <- function (lg) {
df <- filter(cogs, X4 == lg)
unique(df$X3)
}
get_subgroup("Warlpiri")
# For Bowern 285 cognate judgements
setwd("~/Downloads")
cogs <- read_tsv("pny10_285_full.tab", col_names = FALSE)
setwd("~/Desktop/Github/phylo-sig-new/data")
lgs <- read_csv("wordlist_sizes_2020-06-05.csv")
subgroups <- unique(unlist(cogs$X3))
get_subgroup <- function (lg) {
df <- filter(cogs, X4 == lg)
unique(df$X3)
}
lgs$subgroup <- sapply(lgs$tip_label, get_subgroup)
length(unique(lgs$subgroup))
unique(lgs$subgroup)
unlist(unique(lgs$subgroup))
View(filter(cogs, X4=="KuukuYau"))
sort(unlist(unique(cogs$X4)))
lgs[lgs$tip_label=="KuukuYau"]
lgs[lgs$tip_label=="KuukuYau",]
lgs[lgs$tip_label=="KuukuYau", "subgroup"]
lgs[lgs$tip_label=="KuukuYau", "subgroup"] <- get_subgroup("KuukuYa'u")
get_subgroup("KuukuYa'u")
View(filter(cogs, X4=="KuukuYa'u"))
View(filter(cogs, X4=="Kuuku Ya'u"))
View(filter(cogs, X4=="KuukuYa’u"))
lgs[lgs$tip_label=="KuukuYau", "subgroup"] <- get_subgroup("KuukuYa’u")
get_subgroup("KuukuYa’u")
lgs[lgs$tip_label=="KuukuYau", "subgroup"]
lgs[lgs$tip_label=="KuukuYau", "subgroup"] <- "Paman"
lgs
get_subgroup <- function (lg) {
df <- filter(cogs, X4 == lg)
unlist(unique(df$X3))
}
lgs$subgroup <- sapply(lgs$tip_label, get_subgroup)
lgs
sapply(lgs$tip_label, get_subgroup)
vapply(lgs$tip_label, get_subgroup)
as.character(sapply(lgs$tip_label, get_subgroup))
lgs$subgroup <- as.character(sapply(lgs$tip_label, get_subgroup))
lgs[lgs$tip_label=="KuukuYau", "subgroup"] <- get_subgroup("KuukuYa’u")
length(unique(lgs$subgroup))
unlist(unique(cogs$X3))
# Small script to append subgroups from Bouckaert, Bowern and Atkinson (2018) to the Wordlist Sizes csv file
# File paths for Jayden's computer
# For BBA 2018
library(tidyverse)
setwd("~/Desktop/Github/phylo-sig-new/data")
lgs <- read_csv("wordlist_sizes_2020-06-05.csv")
setwd("~/Desktop/Github/PN_treebuilding/Data/subgroups")
subgroups <- lapply(list.files(), function (i) read_tsv(i, col_names = F))
names(subgroups) <- list.files()
names(subgroups) <- gsub(".txt", "", names(subgroups))
get_subgroup <- function (lg) {
sub_list <- character(0)
for(i in 1:length(subgroups)) {
if (lg %in% subgroups[[i]]$X1) {
sub_list <- c(sub_list, names(subgroups)[i])
}
}
sub_list
}
lgs$subgroup <- sapply(lgs$tip_label, get_subgroup)
# For Bowern 285 cognate judgements
setwd("~/Downloads")
cogs <- read_tsv("pny10_285_full.tab", col_names = FALSE)
setwd("~/Desktop/Github/phylo-sig-new/data")
lgs2 <- read_csv("wordlist_sizes_2020-06-05.csv")
subgroups <- unique(unlist(cogs$X3))
get_subgroup <- function (lg) {
df <- filter(cogs, X4 == lg)
unlist(unique(df$X3))
}
lgs2$subgroup <- as.character(sapply(lgs2$tip_label, get_subgroup))
lgs2[lgs$tip_label=="KuukuYau", "subgroup"] <- get_subgroup("KuukuYa’u")
sort(unlist(unique(lgs$subgroup)))
sort(unlist(unique(lgs2$subgroup)))
get_subgroup <- function (lg) {
sub_list <- character(0)
for(i in 1:length(subgroups)) {
if (lg %in% subgroups[[i]]$X1) {
sub_list <- c(sub_list, names(subgroups)[i])
}
}
sub_list
}
get_subgroup("Dyirbal")
library(tidyverse)
setwd("~/Desktop/Github/phylo-sig-new/data")
lgs <- read_csv("wordlist_sizes_2020-06-05.csv")
setwd("~/Desktop/Github/PN_treebuilding/Data/subgroups")
subgroups <- lapply(list.files(), function (i) read_tsv(i, col_names = F))
names(subgroups) <- list.files()
names(subgroups) <- gsub(".txt", "", names(subgroups))
get_subgroup <- function (lg) {
sub_list <- character(0)
for(i in 1:length(subgroups)) {
if (lg %in% subgroups[[i]]$X1) {
sub_list <- c(sub_list, names(subgroups)[i])
}
}
sub_list
}
get_subgroup("Dyirbal")
