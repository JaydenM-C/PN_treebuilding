---
title: "Phonotactic variation in Pama-Nyungan tree inference"
subtitle: 
author: 
site: bookdown::bookdown_site
output:
  bookdown::pdf_document2:
    fig_caption: yes
    keep_tex: yes
    toc: no
    citation_package: biblatex
link-citations: yes
bibliography: references.bib
biblatexoptions: [bibstyle=biblatex-sp-unified, citestyle=sp-authoryear-comp]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(kableExtra)
library(knitr)
```

Summary: This paper evaluates whether phylogenetic tree inference in linguistics is strengthened by the inclusion of phonotactic information. We take ~1400 binary phonotactic variables and several hundred frequency variables and combine them with lexical cognate data from 44 western Pama-Nyungan languages. The study begins with preliminary explores the evolutionary dynamics of the phonotactic data. This is necessary to ascertain the best evolutionary model with which to infer a tree, since this is a novel source of data in linguistic tree inference. The second part of the study compares two models for inferring a Pama-Nyungan phylogeny using Bayesian methods. In one, a phonotactic data partition and lexical cognate partition are used jointly to infer trees. In the other these partitions are kept separate for the purpose of tree inference. Bayes factors for these two models are compared. We find that the combination of phonotactic data with lexical data does not significantly strengthen tree inference, likely owing to deficiencies in the evolutionary model and current computational limitiations. The paper concludes with a discussion of the reasons for this and an outline of future research steps to evaluate whether the present findings represent a true negative or merely limitations of the methodology.

**Notes:**

Bayes factors are robust [@brown_importance_2007]

Introduction {#pn-tree-intro}
================================================================================

_This section needs fleshing out, but not too much. Aim is to keep it sharp and concise_.

Background:

Phylogenies in linguistics are a big deal.

Lots of tree building been happening.

Phylogenies are also crucial for advances in comparative langauge sciences, studies of human history generally.

Data mainly limited to cognates. Some use of structural characters, but these tend to suffer from restricted state space.

In biology, @parins-fukuchi_use_2018 find that combining continuous morphological characters to more traditional, categorical data can strengthen tree inference. An example of integration of continuous morphological data and genomic data @domel_combining_2019.

Prev. study [@macklin-cordes_phylogenetic_2020] found phylogenetic signal in phonotactics. The hypothesis was that phonotactic systems are likely to evolve in an historically conservative way, reflect linguistic phylogenies and therefore be useful for tree inference. That finding was encouraging support for this hypothesis but not definitive proof by any means. Just because something has phylogenetic signal does not mean, by itself, that you can infer phylogenetic trees from it. For example, geography often has a pretty strong phylogenetic signal. In this study, we put the hypothesis to the test by attempting to infer a linguistic phylogeny with the aid of phonotactics.

## Why phonotactics

**revise**

We are motivated to extract frequency datasets for a couple of reasons. Firstly, it allows us to capture a finer grained level of information than binary data would allow. Binary data is more similar to the kind of phonotactic information one might find in a published language grammar, where a description of phonotactics that one would typically encounter involves a series of statements on the (binary) permissibility or otherwise of certain combination of segments. This information does not, however, account for quantitative differences between common, high frequency sequences of segments versus dispreferred sequences that rarely arise in a language's lexicon. There is considerable evidence to suggest that speakers are psychologically attuned to these kinds of phonological frequencies [@coleman_stochastic_1997; @zuraw_patterned_2000; @ernestus_predicting_2003; @albright_rules_2003; @eddington_spanish_2004; @hayes_stochastic_2006; @gordon_phonological_2016]. The second reason is that the relatively rapid, semi-automated extraction of transition frequencies from wordlists captures structural variation between languages at a scale and degree of precision that would be difficult to attain from manual data coding methods (as preferred for the coding of lexical cognate data and grammatical data used in previous linguistic phylogenetic work). @macklin-cordes_phylogenetic_2020 show that this transition frequency dataset contains stronger phylogenetic signal than its binary equivalent. There is one limitation of the frequency transition data, which is that presently we require positive values to use for tree inference (more on evolutionary models and tree inference below). Biphones of zero frequency (recorded as '0' in the binary dataset) get transformed to gaps in the dataset. By including the binary dataset in this study, we retain a distinction between biphones that are impossible in a language (because one or both of the segments are absent from the language's phonemic inventory) and biphones that are possible in principle but are never observed. Our phonotactic data captures information on which phonemic segments may combine immediately adjacent to one another and the frequencies at which they do so. This is phonotactics in the simplest sense, and does not directly capture phonotactic restrictions that depend on sequences beyond two segments, syllable structure or morpheme boundaries. Nevertheless, @macklin-cordes_phylogenetic_2020 confirm that this simple level of phonotactic data is sufficieent to detect strong phylogenetic signal.

Another argument is that our method avoids _observer bias_. We don't have to rely on an expert picking and choosing which parts of a grammatical or lexical system are interesting and worth coding. This is described as an advantage of large-scale extraction of continuous morphological characters in biology too [@wright_systematists_2019]. Another advantage of encoding structural variation with continuous characters over categorical ones: "phylogenetic error is very high for characters with ... very high rates of evolution (due to homoplasy of changes). Continuous characters do not display this relationship as strongly due to their large state space, though more research is needed to demonstrate this effect empirically." [@wright_bayesian_2014]. Applicable to grammatical variables in linguistic phylogenetic tree inference, which show high rates of evolution and lots of homoplasy, due at least in part to tightly contrained state space [@greenhill_evolutionary_2017]. We don't have to worry about correcting for acquisition bias since the datasets reflect the full range of logically possible biphones in every language. We can include invariant sites (where all values are the same. These don't matter much for topology but are important for dating/branch lengths) and we don't need to correct for ascertainment bias [@leache_short_2015].

We use a Bayesian computational approach to infer linguistic phylogenies using BEAST phylogenetic software (v1.10.5) [@suchard_bayesian_2018]. This is similar to earlier work on the Pama-Nyungan phylogeny [@bowern_computational_2012; @bouckaert_origin_2018] which used BEAST2 [@bouckaert_beast_2019]. We selected BEAST over BEAST2 because it offers the ability to infer trees with continuous characters. Throughout, we generally try to follow @bouckaert_origin_2018 as closely as possible. We follow @bouckaert_origin_2018 in constraining the tree topology using clade priors for well-established and commonly accepted Pama-Nyungan subgroups, as established by @ogrady_languages_1966, @muhlhausler_atlas_1996 and @koch_languages_2014 and subsequently recovered in computational phylogenetic analysis by @bowern_computational_2012. Dating the Pama-Nyungan tree is a central focus of @bouckaert_origin_2018, combining lexical cognate data with geographical data and archaeological calibration points to give a best-available estimate of the geographic and temporal point of origin of the family. Accordingly, we retain their calibration prior on the Wati subgroup, which places a 95% probability of the subgroup's origin dating between 3,000-5,000 years, with most of the probability density skewing towards the younger end of that range (a gamma distribution of $\alpha = 2$, $\beta = 359$, with 3,000 year offset) based on a synthesis of archaeological evidence [see @bouckaert_origin_2018, p. 746]. We place a prior on the root age of the Pama-Nyungan family centred on a mean of 5,791 years B.P., following the findings of @bouckaert_origin_2018. 5,791 years is the mean root age of the posterior for their best supported hypothesis on Pama-Nyungan's origins. We model this as a normal distribution (SD = 730) approximating the 95% range of posterior root age estimates. One aspect in which we differ from @bouckaert_origin_2018 is tip dates. @bouckaert_origin_2018 use a birth-death skyline tree model which allows for tip dates to differ and includes a parameter corresponding to the proportion of total taxa sampled at a given point in time. This is reasonable since they use language sources span over 200 years. In contrast, we assume all tips are contemporaneous. In our case, since we restrict attention to relatively modern sources, any extra precision to be gained from including tip dates is not worth the reduced tree model choice in BEAST and extra computational expence.

## Combined cognate and phonotactics tree inference {#pn-tree-combined}

Evolutionary model for phonotactic frequency dataset is more straightforward. We take a standard, lightweight Brownian motion model in which frequency values can wander up or down with equal probability through time. We are limited to this model by software constraints, but that is not a major limitation at this point. Firstly, Brownian motion is a standard starting point in comparable biological studies that jointly infer trees with continuous data. Secondly, it is the same model used in @macklin-cordes_phylogenetic_2020. One difference between @macklin-cordes_phylogenetic_2020 and this study is that @macklin-cordes_phylogenetic_2020 use raw frequency values whereas we use log-transformed frequency values. We observe that biphone transition frequencies tend to be skewed such that lexicons tend to contain relatively few high frequency biphone transitions and many low frequency transitions. It follows then that these biphone transition frequencies are more likely the outcome of an evolutionary process where characters wander along a skewed, lognormal scale than one in which they wander along a normal distribution (although, in practice, it may not matter too much. @macklin-cordes_phylogenetic_2020 find no significant difference in phylogenetic signal using raw values versus log-transformed values). These skewed distributions echo the skewed distributions of single segments observed by @macklin-cordes_re-evaluating_2020. As @macklin-cordes_re-evaluating_2020 makes clear, this does not mean that biphone transition frequencies are necessarily drawn from a lognormal distribution and a more sophisticated maximum likelihood test would be needed to distinguish between the lognormal and several other similarly skewed distribution types. Nevertheless, the lognormal distribution is a sufficient approximation of the skewed distribution of biphone transition frequencies for our purposes in this study.

Thinking briefly about what would be a realistic model of evolution for biphone transition frequencies. We would expect there to be two main forces impacting these frequencies. The first is the introduction of new vocabulary to a language via lexical innovation or borrowing. Each new word entering a lexicon will alter minutely the frequencies of biphone transitions in the language (similarly, transition frequencies will decline as words are replaced or fall out of usage). This is the kind of gradual accumulation of changes that we might expect to follow a Brownian motion-like pattern of evolution (although maybe the rates of going up and down are not equal). Further, since speakers show a preference for high frequency phonotactic sequences over low frequency sequences when coining new words, we might expect this accumulation of changes to follow a kind of 'rich get richer' process which would result in the kind of skewed frequency distributions that we observe. Also, when languages borrow vocabulary, the trend is for foreign words with dispreferred phonotactic sequences to shift towards more natively preferred patterns (sometimes gradually over a long period of time, i.e. look at various French words in English, stress has shifted to English pattern in some but not yet in others), which would strengthen this kind of 'rich get richer' process and also keep phonotactic frequency data historically conservative. The second major force on biphone frequencies is sound change. We would expect sound changes to result in sudden jumps in the frequencies of affected biphones, sometimes to 0 or 1. Our binary characters capture some of these effects to a limited extent. For example, perhaps a language has some frequency value for sequences of a nasal followed by a stop with a different place of articulation. If that nasal undergoes place assimilation, the biphone frequency will drop to 0 and thus disappears as a gap in the frequency dataset since evolutionary model requires non-zero values. On the other hand, this assimilation will be recorded in the binary data as a shift from '1' to '0'. In other instances, biphone characters may shift from missing to present and vice versa in both the frequency and binary datasets. For example, if a contrastive vowel length distinction emerges, certain biphones (namely those with long vowels) will go from being a gap in a language's biphone transition frequency data to some positive, non-missing value. In the case of a merger between short and long vowels, the opposite will be true. Our model, at present, simply does not account well for sound change. In this respect, there is an advantage to studying Australian languages, since Australian languages show uniquely constrained variation in phonological inventories [REFS] (easier to match biphones between languages, less dataset sparsity) and less history of identified sound changes relative to other parts of the world (historical linguists have long turned to sources of historical evidence in other parts of language like morphology etc. [REFS]). We return to this subject in Section \@ref(pn-tree-discussion).

For the cognate data partition, we approximate as much as possible the best supported priors from @bouckaert_origin_2018. We use a covarion model with a relaxed clock and fixed rates across cognate classes.

Methodology
================================================================================

## Research question

This study tests the question of whether or not the addition of phonotactic data strengthens linguistic phylogenetic tree inference. To test this question, we infer a phylogeny of the western branch of Pama-Nyungan languages using lexical cognate data and phonotactic data and repeat this process twice---once in which the phylogeny is inferred jointly from cognate and phonotactic data and once in which separate trees are inferred from cognate data dand phonotactic data. The strength of phylogenetic inference in each instance is evaluated by estimating and comparing log marginal likelihoods for each, and comparing the topologies and posterior clade support values of maximum clade credibility trees. 

## Experimental design

There are four test components in this study: two preliminary test components and two main test components. Preliminary testing consists of (1) evaluating the best-fitting evolutionary model for binary biphone data, and (2) tree inference using cognate data only, essentially aiming to replicate @bouckaert_origin_2018. Model comparison is a regular step in linguistic phylogenetic studies, as typically a number of clock models, site models and other parameters are considered. In this study, the cognate data is sourced from a prior study [@bouckaert_origin_2018] which already evaluated the best-fitting model for this particular set of data. Accordingly, we skip this process and replicate as much as possible the best supported model and priors that @bouckaert_origin_2018 find. It is a different story, however, for the binary biphone data which has not been used previously for phylogenetic tree inference. The novelty of this data source necessitates a thorough evaluation of which evolutionary model can best be applied to it. This is the subject of the first preliminary test. 

The second preliminary test involves inferring a phylogeny using only cognate data from @bouckaert_origin_2018. This test functions as a sanity check to ensure that our phylogenetic model and software implementation, which approximates but does not exactly replicate @bouckaert_origin_2018, produces suitably equivalent results.

These preliminary tests are followed by the main test evaluating the primary research question described above. We use the Bayesian Markov chain Monte Carlo (MCMC) method implemented in BEAST phylogenetic software to infer a phylogeny of western Pama-Nyungan using cognate data, binary biphone data and continuous phonotactic data consisting of sound class transition frequencies. In a second MCMC run, we include two tree models, one inferred with cognate data only and another with phonotactic data only (both binary and continuous). Marginal likelihoods are estimated using the stepping stone sampling method [@baele_accurate_2013]. For each tree model, we produce a maximum clade credibility tree from the posterior sample of trees that BEAST produces and then compare the topologies and clade support values of these.

We conduct one follow-up test after this. To test our suspicion that the binary phonotactic data was contributing undue weight to likelihood calculations without contributing much phylogenetic information, we re-ran the experiment with this data partition removed. In this instance, the second BEAST run contains two tree models, one inferred with cognate data only and one inferred using cognate data and continuous phonotactic data together.

## Language sample

The target language sample, in the first instance, is the 306 Pama-Nyungan language varieties represented in @bouckaert_origin_2018. Of these, we restrict attention to languages meeting the following criteria. Firstly, the language must be represented in the Ausphon Lexicon database [@@round_ausphon-lexicon_2017] from which we source wordlist data. Secondly, the original wordlist data source must have been compiled by a trained linguist from primary fieldwork with living speakers or a combination of fieldwork and archival materials (no sources reconstituted only from archival materials). Thirdly, each wordlist must contain at least 250 lexical items. This leaves a subset of 111 Pama-Nyungan languages. In Preliminary Test 1, where computational demands are relatively minimal, this is the language sample we use. Due to computational constraints associated with large amounts of continuous data and large phylogenies, in the main test we restrict attention to the western branch of the Pama-Nyungan family identified in @bowern_computational_2012 and @bouckaert_origin_2018. This gives a sample of 44 western Pama-Nyungan languages covering nine Pama-Nyungan subgroups. A list of languages and their original sources is available in **APPENDIX REF**.

Preliminary test 1: Evolutionary model for binary biphone data {#prelim-1}
================================================================================

As the number of linguistic phylogenetic studies using lexical cognate data expands, some consistent findings have emerged, for example covarion model seems widely preferred. [check state of the art language comparison article]. However, this is to the best of our knowledge the first attempt at tree inference with binary biphone characters [unless Gerhart tried it?] so we start by embarking on the process of model testing and selection for this novel data type. The aim is to identify a sensible model and set of priors that we can specify for the binary biphone data in subsequent testing.

For each model specification, we run two independent MCMC chains of 25,000,000 iterations, with parameters logged every 10,000 iterations. Log marginal likelihoods are estimated using BEAST's path sampling/stepping stone sampling procedure [@baele_accurate_2013] consisting of 50 path steps of 500,000 iterations, with parameters logged every 10,000 iterations, conducted on each chain then combined to get an overall marginal likelihood estimate (MLE). We conducted autocorrelation and convergence checks using Tracer v1.7.1 software [@rambaut_posterior_2018]. Note that the results here are a preliminary exploration of model parameters to determine the best parameter settings for the tree inference presented in Section \@ref(pn-tree-combined) below. We do not anticipate that binary biphone characters will produce especially high quality or realistic language phylogenies on their own. The goal is to get a handle on how best to model the evolutionary dynamics of this dataset when used in combination with other sources of evidence.

We test a total of 16 models, consisting of each logically possible combination of site and clock model components. We describe each of these alternatives in turn below.

## Binary biphone data

A language's phonotactic system consists of rules governing how phonemic segments may combine into larger syllables and words. To represent phonotactics, we extract data on the presence and frequencies of _biphones_, two-segment sequences, from language wordlists. From each wordlist, we extract data on the presence and absence of _biphones_, sequences of two segments (where each segment is either a phoneme or a word boundary). A biphone is marked '1' if it is present anywhere in a language's wordlist. If the biphone consists of two segments that are part of the language's phonemic inventory (and therefore the biphone could, in principle, occur in the language) but the biphone never occurs, it is marked '0' for absent. If one or both segments in the biphone are not part of the language's phonemic inventory, then it is marked as a gap '-' in the data. A total of 2236 binary biphone characters are extracted.

## Site and clock settings

Site models describe how binary biphone characters evolve through time. The site model is defined by three parameters, giving eight possible combinations to test:

For this stage of evaluation, we fix the clock model to a strict clock (no variation in evolutionary rates between branches) and fix the tree model to a simple calibrated Yule tree model with a uniform birth rate prior (Yule tree models do not allow for extinction events). We then test all eight combinations of three site model parameters: 

  - A simple continuous time Markov chain (CTMC) model (which contains a single estimated parameter that specifies the frequencies with which biphones are gained and lost) versus a covarion model (which allows sites to switch between fast and slow states). The covarion model is the preferred model of lexical cognate evolution in @bouckaert_corrections_2012, @bouckaert_origin_2018 and @kolipakam_bayesian_2018, although @chang_ancestry-constrained_2015 [p. 219] find little difference between them and opt for the increased simplicity of the former model.
  - Empirical character state frequencies versus estimated character state frequencies.
  - Site homogeneity (fixed evolutionary rates across all character sites) versus heterogeneity (estimated using four gamma distributed categories, following @kolipakam_bayesian_2018). For cognate data, @bouckaert_origin_2018 find a better fit with homgenous rates but @kolipakam_bayesian_2018 find a better fit with heterogenous ones.
  
We use Bayes factors to determine the best supported site, clock and tree models. Bayes factors give an indication of the support for one model over another and are calculated by calculating the ratio of the log marginal likelihoods of each model. A Bayes factor of 5 to 20 is taken as substantial support, greater than 20 as strong support, and greater than 100 as decisive [@kass_bayes_1995]. We table Bayes factors comparing each combination of model settings in Table \@ref(tab:site-models). The names of each model indicate site settings as follows: (S)imple CTMC versus (C)ovarion model, e(M)pirical versus e(S)timated character frequencies, (H)omogenous rates versus (G)amma-distributed heterogenous rates. So, for example, the model termed "CMH" consists of a covarion model with empirical frequencies and homogenous rates across all sites.

We test two clock models: A strict clock, in which a single evolutionary rate is fixed across all branches in the tree, and a lognormally-distributed, uncorrelated relaxed clock. This relaxed clock model generally has been found to outperform a strict clock when modelling lexical cognate evolution [@bouckaert_origin_2018; @kolipakam_bayesian_2018]. Clock settings are denoted in Table \@ref(tab:site-models) by 'S' for strict and 'R' for relaxed. So, for example, the model termed "SSG-S" is a simple site model with estimated character frequencies and gamma-distributed heterogenous rates, combined with a strict clock.

For the relaxed clock, we used an uncorrelated lognormal setting with a uniform prior [0,1] following @kolipakam_bayesian_2018. @bouckaert_origin_2018 constrain the upper bound to 1.0E-4 to reduce burn-in time since, in practice, the mean clock value never approaches even that level. We chose the less informative upper bound given the uncertainty of working with a novel data type.

A third Bayesian phylogenetic model component is the tree model which defines the speciation process. Two main alternatives appear frequently in linguistic phylogenetic research. These are birth-death speciation models, which allow for extinction events, and Yule speciation models, which allow birth events only [as preferred in @bowern_computational_2012; @kolipakam_bayesian_2018]. @bouckaert_origin_2018 use a Birth-Death Skyline model which enables tips to be sampled at different dates, but fix the death rate to zero. This is reasonable since they use language sources span over 200 years. Throughout this study, we follow this precedent by using a birth-death model with the death rate set to zero. However, instead of including different tip ages, we assume all tips are contemporaneous and set their ages to 0, which is not strictly accurate since original wordlist sources do vary in age. In our case, since we restrict attention to relatively modern sources, any extra precision to be gained from including tip dates is not worth the reduced tree model choice in BEAST and extra computational expense. One additional parameter that we do include instead is an incomplete sampling parameter to account for the fact that our language sample is only a subset of the full 306 languages included in @bouckaert_origin_2018. this incomplete sampling parameter is set to 0.36 in this preliminary test ($\frac{111}{306}$). 

## Results {#results-prelim-1}

Bayes factors of pairwise comparisons between candidate models are listed in Table \@ref(tab:site-models). The covarion model overwhelmingly outperforms the simple CTMC model in all instances. Furthermore, there is support for allowing evolutionary rates to vary across character sites. Unfortunately, this great increase in parameters results in a corresponding increase in computational demand. Models with heterogenous rates require 3--4 times as long as equivalent models with fixed rates. Secondly, there is decisive support for estimating character state frequencies rather than simply taking the observed frequencies when the covarion model is used, although the opposite is true with a CTMC model. A covarion model with estimated frequencies and homogenous evolutionary rates will score higher than a model where rates are allowed to vary but empirical frequencies are used. All up, we determine the best site model to be a covarion model with estimated frequencies and rate heterogeneity.

With regards to the clock model, site models paired with a relaxed clock tend to do better than their direct equivalents paired with a strict clock, though covarion models with homogenous rates are exceptions. The best site model, denoted 'CSG' (covarion, estimated frequencies, gamma heterogenous rates), scores decisively higher than all others regardless of which clock model is used. The 'winning' model, which we proceed to apply to binary biphone data throughout the rest of this study, is the CSG model with a relaxed clock ('CSG-R').

```{r site-models-old}
MLEs <- tibble(model = c("SMH-SY", "SSH-SY", "SMG-SY", "SSG-SY",
                         "CMH-SY", "CSH-SY", "CMG-SY", "CSG-SY"),
               MLE = c(-16143, -16149, -14866, -14830, 31068, 82019, 78761, 152322))
BFs <- lapply(1:nrow(MLEs), function (x) unlist(sapply(1:nrow(MLEs), function (y) {bf <- MLEs[x,2] - MLEs[y,2];
                                                                                   names(bf) <- MLEs[y,1];
                                                                                   bf})))
names(BFs) <- MLEs$model
BFs_table <- tibble(`Site model` = MLEs$model, bind_rows(BFs))
BFs_table[BFs_table == 0] <- NA
options(knitr.kable.NA = "--")
#kable(BFs_table, digits = 2, format = "latex", booktabs = TRUE, format.args = list(big.mark = ","), linesep = c('', '', '', '\\addlinespace'), caption = "Bayes factors for different site models. Each Bayes Factor represents the support for one model (listed left) against another (listed top). A positive value indicates the first model (left) is supported, and conversely, a negative value indicates the second model (top) is supported. A value over 100 is considered decisive.")
```

```{r clock-models-old}
MLEs <- tibble(model = c("CMG-R", "CMG-S", "CMH-R", "CMH-S",
                         "CSG-R", "CSG-S", "CSH-R", "CSH-S",
                         "SMG-R", "SMG-H", "SMH-R", "SMH-S",
                         "SSG-R", "SSG-S", "SSH-R", "SSH-S"),
               MLE = c(45102, 24828, 571, 24356,
                       78942, 62026, 2685, 23068,
                       -14695, -14864, -15947, -16148,
                       -14691, -14830, -15934, -16144)
               )

clock_bfs <- function () {
  
}
#relaxed_vs_strict <- tibble(model = c("CMG", "CMH", "CSG", "CSH",
#                                      "SMG", "SMH", "SSG", "SSH"),
#                            bf = sapply(seq(1, 15, by = 2), 
#                                        function (i) {MLEs[i,2] + MLEs[(i+1), 2]})
#                            )
```

```{r site-models}
MLEs <- tibble(model = c("CMG-R", "CMG-S", "CMH-R", "CMH-S",
                         "CSG-R", "CSG-S", "CSH-R", "CSH-S",
                         "SMG-R", "SMG-S", "SMH-R", "SMH-S",
                         "SSG-R", "SSG-S", "SSH-R", "SSH-S"),
               MLE = c(45102, 24828, 571, 24356,
                       78942, 62026, 2685, 23068,
                       -14695, -14864, -15947, -16148,
                       -14691, -14830, -15934, -16144)
               )

BFs <- lapply(1:nrow(MLEs), function (x) unlist(sapply(1:nrow(MLEs), function (y) {bf <- MLEs[x,2] - MLEs[y,2];
                                                                                   names(bf) <- MLEs[y,1];
                                                                                   bf})))
names(BFs) <- MLEs$model

BFs_table <- tibble(`Site model` = MLEs$model, bind_rows(BFs))
BFs_table[BFs_table == 0] <- NA

options(knitr.kable.NA = "--")

kable(BFs_table, digits = 2, format = "latex", booktabs = TRUE, format.args = list(big.mark = ","), linesep = c('', '', '', '\\addlinespace'), caption = "Bayes factors for different site models. Each Bayes Factor represents the support for one model (vertical axis) against another (horizontal). A positive value indicates the first model (left) is supported, and conversely, a negative value indicates the second model (top) is supported. A value over 100 is considered decisive.") %>% landscape() %>% kable_styling(font_size = 8)
```

One limitation to note is that we have not considered the stochastic Dollo model, which has been implemented with some success for cognate data in linguistics [@bowern_computational_2012] (although the covarion model was subsequently found to be better in @bouckaert_origin_2018). Stochastic Dollo only allows characters to spring into existance once and any losses are permanent. Such a model is perhaps a bit more realistic for cognates, since the state space of possible words is practically infinite (i.e. the chance of different people inventing the same word for the same thing independently is low, although of course it does happen sometimes)[^1]. By contrast, there are only so many possible biphone combinations, many unrelated/distantly related languages share biphones (consider, for example, shared biphones between English and Pama-Nyungan languages) and it seems unreasonable to assume a single common point of origin for all of them, hence why we disregarded this model for this study.

[^1]: That said, stochastic Dollo is not particularly realistic for cognates either since it does not allow for borrowing, which manifests as two independent origin points when plotted on a phylogenetic tree. The presence of borrowing likely explains why the covarion model tends to work better than stochastic Dollo in linguistic phylogenetic studies. As an aside, an ideal phylogeographic model of cognate evolution would allow for independent points of origin at two rates of likelihood: a very low rate of likelihood of the cognate originating independently anywhere throughout the tree (capturing the likelihood of undetected chance resemblances coded as cognates), and a relatively high likelihood of a cognate independently originating in languages that are geographically adjacent to a cognate where the cognate is already present (to capture effectively borrowing events rather than genuine instances of convergent evolution). However, this would almost certainly be computationally expensive.

```{r tree-models-old}
MLEs <- tibble(model = c("CSG-SY", "CSG-RY", "CSG-SB", "CSG-RB"),
               MLE = c(152322, 227436, 161893, 168628))

BFs <- lapply(1:nrow(MLEs), function (x) unlist(sapply(1:nrow(MLEs), function (y) {bf <- MLEs[x,2] - MLEs[y,2];
                                                                                   names(bf) <- MLEs[y,1];
                                                                                   bf})))
names(BFs) <- MLEs$model

BFs_table <- tibble(`Clock/tree model` = MLEs$model, bind_rows(BFs))
BFs_table[BFs_table == 0] <- NA

options(knitr.kable.NA = "--")

#kable(BFs_table, digits = 2, format = "latex", booktabs = TRUE, format.args = list(big.mark = ","), linesep = c('', '\\addlinespace'), caption = "Comparison of models with different clock and tree settings.")
```

Preliminary test 2: Tree inference using cognate data only {#prelim-2}
================================================================================

This second preliminary test aims to replicate the results of @bouckaert_origin_2018 using the same cognate data and approximately the same evolutionary model. The goal is to ensure that our particular software implementation and slight differences in implementation of the evolutionary model do not unduly impact the results, which we then use as a baseline for comparison in the main test below.

Differences between the implementation of this test and @bouckaert_origin_2018 are as follows. Firstly, the language sample is greatly reduced. Owing to the computational demands of inferring a large phylogeny with a large quantity of continuous-valued data, the language sample for the main test is reduced to 44 western Pama-Nyungan languages and so this is the language sample we use here. Secondly, we include an incomplete sampling parameter of 0.537, to account for the fact that our language sample covers 44 of the 82 languages in the western branch of the @bouckaert_origin_2018 phylogeny. Another difference is that, as described above, we do not include divergent tip ages in our model, although the 44 languages we use are sourced from modern sources anyway. Finally, we run the model in BEAST sofware (v1.10.5) [@suchard_bayesian_2018] rather than BEAST2 [@bouckaert_beast_2019]. We selected BEAST over BEAST2 because it offers the ability to infer trees with continuous characters (necessary for the main test below).

We follow @bouckaert_origin_2018 in constraining the tree topology using clade priors for well-established and commonly accepted Pama-Nyungan subgroups, as established by @ogrady_languages_1966, @muhlhausler_atlas_1996 and @koch_languages_2014 and subsequently recovered in computational phylogenetic analysis by @bowern_computational_2012. Dating the Pama-Nyungan tree is a central focus of @bouckaert_origin_2018, combining lexical cognate data with geographical data and archaeological calibration points to give a best-available estimate of the geographic and temporal point of origin of the family. Accordingly, we retain their calibration prior on the Wati subgroup, which places a 95% probability of the subgroup's origin dating between 3,000-5,000 years, with most of the probability density skewing towards the younger end of that range (a gamma distribution of $\alpha = 2$, $\beta = 359$, with 3,000 year offset) based on a synthesis of archaeological evidence [see @bouckaert_origin_2018, p. 746]. We place a flat, uniform prior on the root age of the western Pama-Nyungan phylogeny of 3,000--7,000 years. This covers the time period from the youngest possible age of the Wati subgroup to the oldest end of the age range of the Pama-Nyungan family as a whole, under the best supported hypothesis of the origin of the Pama-Nyungan family in @bouckaert_origin_2018 (the mean root age in that study is 5,791 years). If the Wati age prior and best supported Pama-Nyungan root age in @bouckaert_origin_2018 are accepted, it follows that this is the logically maximal age range in which the origin of the western Pama-Nyungan branch must lie.

## Results {#results-prelim-2}

We run four independent MCMC chains of 100 million iterations each and discard the initial 10% burn-in. Logs were inspected and combined in Tracer (v1.7.1) to confirm that each run converged properly in the same probability space and that ESS values for all parameters were sufficiently high (>200). Chains 1--2 converge nicely in the same space, with all ESS values over 800. Chain 3 got stuck in a local optimum in the state space and chain 4 failed to converge, so these were discarded. Chains 1--2 were combined with 10% burn-in on each, giving a 180-million-state tree sample and combined ESS figures all greater than 1,900. A maximum clade credibility tree was produced using TreeAnnotator (v1.10.4). This is displayed in Figure \@ref(fig:cogs-vs-bba2018) next to the same subset of languages from the maximum clade credibility tree in @bouckaert_origin_2018. We recover largely the same topology with some minor differences. These discrepencies seem approximately equivalent to the level of discrepencies between the @bouckaert_origin_2018 phylogeny and phylogenies from @bowern_computational_2012 and @macklin-cordes_phylogenetic_2020.

Western Arrernte, the sole representative of the Arandic subgroup, shifts places among deeper nodes in the tree. The internal structure of the Ngumpin-Yapa subgroup also differs, which is interesting since the internal structure of Ngumpin-Yapa also shifts between @bowern_computational_2012 and @bouckaert_origin_2018. In other words, in this instance divergences exist in a subgroup of the tree where there was already uncertainty between different analyses. Overall, notwithstanding these discrepancies, we are content that our model and method is working as it should with cognate data.

```{r cogs-vs-bba2018}
include_graphics("fig/cogs_vs_bba2018.pdf")
```

Main test: Tree inference with phonotactic data
================================================================================

## Data

There are three main sources of data for this experiment. One is cognate data from @bouckaert_origin_2018, to which we apply an evolutionary model following @bouckaert_origin_2018, as evaluated in Preliminary Test 2 (Section \@ref(prelim-2)). There are two sets of phonotactic data, one binary and one continuous. Binary biphone data, which codes the presence or absence of biphones---sequences of two phonemes---in each language, is included with the best supported evolutionary model evaluated in Preliminary Test 1 (Section \@ref(prelim-1)). Finally, we use a dataset of continuous phonotactic characters coding frequencies of transitions between natural sound classes. The data extraction process is detailed further as follows. Each consonant phoneme appearing in our wordlist data is binned into two natural classes, one for place of articulation and one for manner of articulation. Place classes are labial, dental, alveolar, retroflex, palatal and velar. Manner classes are obstruent, nasal, vibrant, lateral, glide, and rhotic glide. For the purposes of this experiment, we group all vowels into a single 'vowel' class and also include word boundaries. The choice of place and manner natural classes is based on well-established principles of organisation among segments in Australian languages [@dixon_languages_1980; @hamilton_phonetic_1996; @baker_word_2014; @round_segment_2021; @round_phonotactics_2021]. From each wordlist, we extract the frequency of a sound class $x$ followed by a sound class $y$, relativized over all instances of sound class $x$. For use in BEAST, we logit-transform all the data to move from a 0--1 frequency interval to the real line. To include 0 and 1 frequency values in the logit-transformation, we follow a standard procedure of converting 0 values to $\frac{min}{2}$, i.e. half the smallest non-zero value, and converting 1 values to $0.5 (1 + max)$, i.e. half way between 1 and the maximum value less than 1. The evolutionary model applied to sound class transition frequency data in BEAST is a simple Brownian motion model which allows character values to wander up or down with equal possibility. We initially considered applying a single multivariate Brownian motion model to all continuous traits, however, the computational memory and time required by a multivariate Brownian motion model scales exponentially as the number of characters is increased. Instead, we fit a Brownian motion model to each character individually. This greatly increases the number of parameters in the overall model and potentially makes it less realistic, but it keeps the project computationally feasible. We return to this topic further in the discussion.

The choice of phonotactic data warrants brief further comment. We select sound class transition frequency data for a few reasons. One is that it partially, though not entirely, accounts for a lack of independence between biphone characters. This is because phonological rules, phonotactic restrictions and historical sound changes typically affect natural classes of phonemes rather than individual phonemes. This is not a perfect solution---sound classes themselves are independent from one another to varying degrees. A second reason is that @macklin-cordes_phylogenetic_2020 find a stronger degree of phylogenetic signal in sound class transition frequency data compared to transition frequencies between individual phonemes. A third reason is computational. A dataset of continuous characters equivalent in size to the binary biphone dataset would increase the computational time required to run BEAST by orders of magnitude, rendering the study impractical.

As mentioned in Section \@ref(prelim-2), we reduce the language sample to 44 western Pama-Nyungan languages. This was necessary to keep the computational demands of the experiment reasonable. We selected the western branch of Pama-Nyungan due to it being relatively well-attested in modern sources compared to those in, for example, the south-east of Australia where language documentation is more often reliant on archival sources due to the disproportionate impact of colonialism in this part of the continent.

We run BEAST on two phylogenetic models: a 'linked' model, which contains a single tree likelihood term calculated using all cognate and phonotactic data, and a 'seperate' model, which contains two tree likelihood terms, one calculated using cognate data only and the other using phonotactic data only (both binary and continuous). We run ten independent MCMC chains of 100 million iterations on each model, inspect and combine the results, estimate marginal likelihoods for each of the 'linked' and 'separate' models and generate three maximum clade credibility trees (one for the 'linked' model, and one each for the cognate-only and phonotactics-only elements of the 'separate' model).

## Results {#main-results}

One first observation is that the MCMC process in BEAST tends to get stuck in local optima within the probability space and occasionally fails to converge as well. When this became clear, we increased the number of independent chains from an initial four to ten. Inspecting the joint probability traces for each of the linked model's ten runs, we find one clearly preferred area of the state space (Figure \@ref(fig:linked-all-trace)). We remove two clear outliers stuck in local optima above and below the others. Two additional runs (visible in Figure \@ref(fig:linked-all-trace) as two overlapping, slightly bimodal distributions, just to the left of the bulk of other chains) are removed since, although they overlap considerably with the others, they too seem to represent a distinct local optimum in the state space (one of these also failed to reach stable convergence). Three more chains failed to reach stable convergence after a reasonable (10--20%) burn-in period and had to be removed. This leaves three stable chains with suitable ESS values and consistent areas of convergence (the three tallest, central peaks in Figure \@ref(fig:linked-all-trace)). After discarding 10% burn-in, we are left with a combined 270-million-state analysis.

BEAST computes two marginal likelihood estimates, one via the path sampling method [@baele_improving_2012] and one via the stepping stone sampling method [@baele_accurate_2013]. In normal operation these two estimates should be roughly equivalent. In this instance, the log marginal likelihood estimates for the combined analysis are 598,885 (estimated via path sampling) and 988,231 (estimated via stepping stone sampling). Unfortunately, it is unclear whether or not these log MLE figures are meaningful. Log MLEs for each individual chain vary between 459,380 and 672,466 which is much more variation than we would expect, given that a difference of 20 is generally considered significant. Given that all chains represent the same data and model and converge in approximately the same space, we would expect their log MLEs to be around the same and certainly not as divergent as this. We discuss this further below.

```{r linked-all-trace, fig.cap='insert caption', fig.show='hold', out.width='50%'}
include_graphics("fig/joint_trace_ch1-10.pdf")
include_graphics("fig/joint_trace_dens_ch1-10.pdf")
```

The separate model, in which two trees are sampled at each step, one inferred using only cognate data and one inferred using only phonotactic data, fails to reach stable convergence and gives unacceptably low ESS figures in most instances. With a burn-in of 15%, as per the linked model above, only 3 chains give a stable posterior sample with satisfactory ESS values. A fourth stabilises after a 20% burn-in, and three others eventually stabilise in similar areas of the probability space to the others, but only after burn-in values of 50%, 60% and 70%. We apply a consistent 20% burn-in to the four most stable chains and discard the rest. Two of these converge in the same area while the other two converge in spaces of slightly lower joint likelihood. On this evidence, it is not entirely clear which is the most correct posterior distribution. We accept the two higher likelihood chains space as it makes the study's null hypothesis deliberately harder to disprove (the null hypothesis that the joint model is no better than the separate model is harder to disprove if we raise the bar set by the separate model). This gives a posterior sample of 160 million states and a marginally satisfactory ESS of 100 or greater for all parameters. Maximum clade credibility trees for each of the two tree elements---one inferred only with cognate data and the other inferred only with phonotactic data---are depicted in Figure \@ref(fig:separate-cogs-vs-phonotactics).

```{r separate-all-trace, fig.cap='insert caption', fig.show='hold', out.width='50%'}
include_graphics("fig/sep_trace_ch1-10.pdf")
include_graphics("fig/sep_trace_dens_ch1-10.pdf")
```



The log MLEs for the separate model are 348,287 (estimated via path sampling) and 568,402 (estimated via stepping stone sampling). These MLEs can be compared with MLEs for the linked model in Table \@ref(tab:linked-vs-separate-mles). The linked and separate models can be compared using Bayes factors, following Equation \@ref(eq:bf).

\begin{equation}
BF = log(MLE_{linked}) - log(MLE_{separate})
(\#eq:bf)
\end{equation}

The sign of the Bayes factor indicates which model is preferred. Bayes factors testing support for the linked model over the separate model are give in Table \@ref(tab:linked-vs-separate-bfs). Using both path sampling and stepping stone sampling methods, the Bayes factors seem to indicate decisive support for the linked model over the separate model. At face value, these figures are evidence for the hypothesis that including quantitative phonotactic data with more traditional cognate data can strengthen phylogenetic tree inference in linguistics. However, given the extreme divergences between MLE estimates from chain to chain and between MLE inferential methods, this evidence should be considered tenuous at best.

```{r linked-vs-separate-mles}
MLEs <- tibble(Model = c("Linked", "Separate"),
               Path = c(598885, 348287),
               `Stepping stone` = c(988231, 568402)
               )

kable(MLEs, format = "latex", booktabs = TRUE, format.args = list(big.mark = ","), caption = "Marginal likelihood estimates (MLEs) estimated via path sampling and stepping stone sampling methods for linked and separate phylogenetic models.")
```

```{r linked-vs-separate-bfs}
BFs <- tibble(Method = c("Path sampling", "Stepping stone"),
              BF = c(250598, 419829))

kable(BFs, format = "latex", booktabs = TRUE, format.args = list(big.mark = ","), caption = "Bayes factors indicating support for the linked model over the separate model.")
```

Another way to evaluate these results is to consider the topologies and posterior support values of maximum clade credibility trees. In Figure \@ref(fig:covs-vs-linked-all), we compare the maximum clade credibility Section \@ref(prelim-1). The linked model posits Western Arrernte as the outermost taxon, branching off first from all other subgroups. This is different to the cognates-only model in Section \@ref(prelim-1) but in line with @bouckaert_origin_2018. The trees are largely congruent although there are some shifts in internal structure in some subgroups. The internal structure of Ngumpin-Yapa shifts once again---the Yapa branch (Warlpiri and Warlmanpa) gets split in the linked model. Overall, there is a general flattening of the tree structure in the linked model, approaching a star phylogeny. One possibility is that the tree structure is being flattened by the addition of the binary phonotactic data. As discussed, this sample of western Pama-Nyungan languages share largely homogenous phoneme inventories and similar phonotactics in binary, permissibility terms. The binary data is relatively low resolution and might be masking phylogenetically informative variation between languages. That said, for the lower order topological structure that is present, the linked model tends to give good posterior support values, with a couple of exceptions. Perhaps unsurprisingly, Ngumpin-Yapa is an exception with very low support values. Another exception is the subgroup of Warnman, Kartujarra and Yulparija in the Wati clade. In other cases though, the addition of phonotactic data in the linked model seems to strengthen some support values, for example, within the Kanyara-Mantharta (languages listed Purduna--Tharrgari in Figure \@ref(fig:cogs-vs-linked-all)) and Kartu (Badimaya--Nhanta) subgroups.

```{r cogs-vs-linked-all}
include_graphics("fig/cogs_vs_linked_all.pdf")
```

The flattening effect of the phonotactic data is evident when MCC trees are calculated for each of the two tree elements of the separate model. Recall that the separate model includes two separate tree elements---one inferred with cognate data only and one inferred with phonotactic data only (both binary and continuous). Maximum clade credibility trees are inferred for each of these elements and plotted in Figure \@ref(fig:separate-cogs-vs-phonotactics-all). Side-by-side, the loss of intermediate tree-like structure is apparent in the phonotactics-only MCC tree. It is perhaps unsurprising then that the linked model, in which a single tree is inferred from all the data together, produces an intermediate level of tree-likeness, less tree-like than the cognates-only model but not as star-like as the phonotactics-only tree in the separate model.

```{r separate-cogs-vs-phonotactics-all, fig.cap='Insert caption here. MCC trees from separate model. Cognates on left, phonotactics on right.'}
include_graphics("fig/separate_cogs_vs_phonotactics_alldata.pdf")
```

Likely need to run for much longer and more times, with operators altered to allow bigger jumps in order to escape optima.


Main test follow-up: Removing binary biphone data
================================================================================


Discussion {#pn-tree-discussion}
================================================================================

Discussion in biology regarding combination of morphological and genomic datasets. "Simultaneous" approach where both morphological and genomic data are used jointly to infer the tree versus "scaffolding" approach where only genomic data is used to infer tree topology, then morphological data is used to assess e.g. dating (using fossil record) while being constrained to genomic tree topology [@lee_morphological_2015]. Must be aware of the potential circularity of tracing the evolution of characters on a phylogeny which was itself partly based on those characters [@de_queiroz_including_1996].

Limitations:

  - Logical dependencies between variables (because of sound changes, phonotactic restrictions affecting natural classes)
  - Logical dependencies between binary/continuous partitions (non-gap in freq data = 1 in binary data. 0 in binary data = gap in freq data)
  - Didn't account for sound change
  - Limitations of Brownian motion model
  
If we get a negative result (no significant difference between trees inferred with/without phonotactic data partition) then I would speculate that it's probably got a lot to do with the inability of our Brownian motion evolutionary model to capture the effects of sound change, which would manifest as sudden jumps in frequencies.

If we get a positive result, then we would advocate for the use of phonotactic data in combination with other sources of evidence, such as cognate data, to infer linguistic phylogenies. 

  - Could be used to help resolve phylogenetic conflicts in places where there is more phylogenetic uncertainty. Could be used to help with dating and branch lengths in places where otherwise the topology is quite well understood.
  - Could help in under-resourced places that don't have as much lexical data. Studies of Pama-Nyungan phylogeny have benefitted from reasonably extensive cognate coding over nearly 300 meaning classes, but a lot of places will be limited to the scale of Swadesh lists or even less. (The opposite is true in biology, where morphological datasets make up ever shrinking proportion of total combined dataset when combined with genomic datasets that keep getting bigger)
  - Could be used for quick and dirty tree inference where some phylogenetic information is required/better than nothing (for example, using phylogenetic comparative methods) but doesn't necessarily have to be perfect. e.g. could combine with very small lexical datasets/automatic cognate identification. Perhaps could be combined with, e.g. glottolog classifications to get something consistent with glottolog tree but fully resolved.

\newpage
  
```{r cb-2015-vs-bba2018}
include_graphics("fig/cb2015_vs_bba2018.pdf")
```

```{r cogs-vs-cb2015}
include_graphics("fig/cogs_vs_cb2015.pdf")
```



```{r bba2018-vs-linked-all}
include_graphics("fig/bba2018_vs_linked_all.pdf")
```

```{r cogs-vs-linked}
include_graphics("fig/cogs_vs_linked.pdf")
```

```{r linked-all-vs-linked}
include_graphics("fig/linked_all_vs_linked.pdf")
```



Conclusion
================================================================================
