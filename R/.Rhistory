lang5 <- c(CoopersCreek = 120)
lang6 <- c(GlenInnes = 120, GraniteRange = 120, Hawkesbury = 120, Janday = 120, Kalaamaya = 120, KingsCreekandtheGeorginaRiver = 120, LakeHindmarsh = 120, LowerBurdekin = 120, NedsCornerStation = 120, PytuReach = 120, RoxburghDowns-LowerGeorgina = 120, Tambo = 120, Tenterfield = 120, UpperParoo = 120, Wanamara = 120)
lang6 <- c(GlenInnes = 120, GraniteRange = 120, Hawkesbury = 120, Janday = 120, Kalaamaya = 120, KingsCreekandtheGeorginaRiver = 120, LakeHindmarsh = 120, LowerBurdekin = 120)
lang7 <- c(NedsCornerStation = 120, PytuReach = 120, RoxburghDowns-LowerGeorgina = 120, Tambo = 120, Tenterfield = 120, UpperParoo = 120, Wanamara = 120)
lang7 <- c(NedsCornerStation = 120, PytuReach = 120, `RoxburghDowns-LowerGeorgina` = 120, Tambo = 120, Tenterfield = 120, UpperParoo = 120, Wanamara = 120)
c(lang1,lang2,lang3,lang4,lang5,lang6,lang7)
yearsBP <- c(lang1,lang2,lang3,lang4,lang5,lang6,lang7)
View(tibble(lang = names(yearsBP), year = values(yearsBP)))
library(tidyverse)
View(tibble(lang = names(yearsBP), year = values(yearsBP)))
View(tibble(lang = names(yearsBP), year = yearsBP))
View(tibble(lang = names(yearsBP), year = yearsBP + 20))
remotes::install_github(/tjmahr/readtextgrid)
remotes::install_github("/tjmahr/readtextgrid")
devtools::install_github("tjmahr/readtextgrid")
library(tinytex)
install.packages(c("ade4", "adegenet", "adehabitatHR", "adehabitatLT", "adehabitatMA", "adiv", "animation", "assertthat", "backports", "BAMMtools", "bayesplot", "bibtex", "BiocManager", "biomod2", "bit", "blob", "blogdown", "bookdown", "boot", "bridgesampling", "brms", "broom", "callr", "car", "carData", "checkmate", "citr", "Claddis", "class", "classInt", "cli", "cluster", "coda", "codetools", "colorspace", "commonmark", "countrycode", "covr", "crul", "cubature", "curl", "DAMOCLES", "data.table", "data.tree", "DBI", "dbplyr", "DDD", "deldir", "dendextend", "deSolve", "devtools", "DiagrammeR", "digest", "dispRity", "diversitree", "docopt", "dplyr", "DT", "dtplyr", "e1071", "earth", "ecodist", "entropart", "enveomics.R", "evaluate", "expm", "FactoMineR", "fansi", "farver", "forcats", "foreach", "foreign", "fs", "future", "future.apply", "gamlss", "gamlss.dist", "gdalUtils", "gdtools", "geiger", "geojson", "geojsonio", "geojsonlint", "geometry", "geomorph", "ggpubr", "ggraph", "ggridges", "ggthemes", "gh", "git2r", "globals", "gmp", "goftest", "gplots", "gridGraphics", "gtable", "haven", "hexbin", "highr", "Hmisc", "htmlTable", "htmltools", "httpuv", "httr", "igraph", "jpeg", "jqr", "jsonlite", "jsonvalidate", "KernSmooth", "knitr", "koRpus.lang.en", "later", "lattice", "leaflet", "leafpop", "leaps", "limSolve", "lintr", "listenv", "loo", "lpSolve", "manipulateWidget", "maptools", "markdown", "MASS", "Matrix", "mgcv", "mime", "mnormt", "modelr", "mongolite", "msm", "multcomp", "multcompView", "mvMORPH", "mvtnorm", "ndjson", "NHPoisson", "nlme", "nloptr", "nnet", "numDeriv", "openssl", "openxlsx", "OUwie", "paleotree", "pbapply", "PCPS", "phyclust", "phylobase", "phylocomr", "phylosignal", "picante", "pillar", "pkgbuild", "pkgload", "plotrix", "poibin", "polspline", "prettyunits", "pROC", "processx", "promises", "protolite", "quadprog", "quantreg", "R.cache", "R.methodsS3", "R.oo", "R.utils", "raster", "rasterVis", "ratematrix", "rcompanion", "RcppArmadillo", "RcppEigen", "RcppProgress", "RCurl", "readtextgrid", "readxl", "RefManageR", "reprex", "reticulate", "rgdal", "rgeos", "rgexf", "rgl", "rmapshaper", "rmarkdown", "rmetasim", "Rmpfr", "rms", "rncl", "RNeXML", "rorcid", "roxygen2", "rpart", "rredlist", "RRPP", "rsconnect", "RSQLite", "rstan", "rstudioapi", "rticles", "Rttf2pt1", "rvcheck", "rvest", "satellite", "scales", "segmented", "selectr", "servr", "sf", "shiny", "shinyjs", "sn", "solrium", "sp", "spam", "SparseM", "spatstat", "spatstat.data", "spatstat.utils", "spData", "StanHeaders", "stringdist", "stringi", "subplex", "SuppDists", "survival", "svglite", "SYNCSA", "taxa", "taxize", "testthat", "threejs", "tidyr", "tidyselect", "tidytree", "tidyverse", "tinytex", "treedater", "tufte", "units", "usethis", "uuid", "V8", "vctrs", "VGAM", "visNetwork", "vitae", "webshot", "whisker", "xaringan", "xfun", "XML", "xml2", "xtable", "xts", "yaml", "zoo"))
install.packages("knitr")
install.packages("tidyverse")
install.packages("poweRlaw")
install.packages("bookdown")
tinytex::tlmgr_install("texlive-generic-extra")
tinytex::uninstall_tinytex()
library(tinytex)
install_tinytex()
install.packages(c("citr", "cowplot", "extrafont", "ggrepel", "kableExtra"))
tlmgr_update()
library(tinytex)
tlmgr_update()
install.packages("tinytex")
install.packages("tinytex")
library(tinytex)
reinstall_tinytex()
print("Hello, world!")
warnings()
warnings()
print("Hello, world!")
install.packages("caper")
caper::phylo.d()
?caper::phylo.d
caper::phylo.d
dat <- read("https://github.com/thimotei/CFR_calculation/blob/poisson_GAMs/global_estimates/data/all_together_clean.rds?raw=true")
dat <- load("https://github.com/thimotei/CFR_calculation/blob/poisson_GAMs/global_estimates/data/all_together_clean.rds?raw=true")
dat <- load("https://raw.github.com/thimotei/CFR_calculation/blob/poisson_GAMs/global_estimates/data/all_together_clean.rds")
dat <- load_git("global_estimates/data/all_together_clean.rds")
tinytex::reinstall_tinytex()
tinytex::tlmgr_install("biber")
tinytex::uninstall_tinytex()
tinytex::install_tinytex()
tinytex::tl_pkgs()
library(tinytex)
uninstall_tinytex()
install_tinytex()
tlmgr_install("biber")
tlmgr_update("biber")
tlmgr_update()
uninstall_tinytex()
library(tinytex)
install_tinytex()
We apply the $D$ test individually to each character in the dataset that meets two conditions: at least 50 non-missing values (due to the aforementioned reliability issue with sample sizes smaller than this) and at least one instance of variation (we do not test characters where all languages share identical 1 or 0 values). Given the extensive history of description of Australian languages as phonotactically homogenous, our prior expectation is that testing binary data will fail to yield significant phylogenetic signal. Indeed, we might expect that $D$ will fall significantly below 0, indicating that values are clumped among tips on the reference phylogeny even more conservatively than would be expected if they had evolved in the same phylogenetic pattern as lexical data.
install.packages("bookdown")
tinytex::tlmgr_install("textcase")
library(tidyverse)
setwd("~/Desktop/Github/PN_treebuilding/R")
bindat <- read_csv(datfile)
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data", "biphone_binary"))[1]
bindat <- read_csv(datfile)
bindat <- read_csv(paste0("../Data/" datfile, ".csv"))
bindat <- read_csv(paste0("../Data/", datfile, ".csv"))
bindat <- read_csv(paste0("../Data/", datfile))
NAs <- colsums(is.na(bindat))
NAs <- colSums(is.na(bindat))
length(NAs[NAs == 111])
(NAs[NAs == 111])
names(NAs[NAs == 111])
library(Ausphonlex)
extract_freq_dataset()
extract_freq_dataset
1s <- colSums(bindat, na.rm = T)
ones <- colSums(bindat, na.rm = T)
ones <- colSums(bindat[,-1], na.rm = T)
bindat[2]
View(bindat[,2])
View(bindat[,3])
summary(bindat[,2])
summary(bindat[,3])
summary(bindat[,1])
summary(bindat[,4])
length(ones[ones == 1])
length(ones[ones == 110])
length(ones[ones == 111])
uniquelength <- sapply(bindat, function(x) length(unique(x[!is.na(x)])))
?elect_if
select_if
?select_if
df <- select_if(bindat, sum > 1 )
metadata <- read_csv("~/Desktop/Github/erichround/Ausphonlex/dbs/Map-DB-Wordlists.csv")
View(metadata)
colnames(metadata)
# Data wrangling
# Jayden Macklin-Cordes
# # # # # # # # # # # # #
library(tidyverse)
library(phonlex)
library(Ausphonlex)
# Load Ausphonlex
aus <- ausphonlex_v0.6.2
# Get wordlist sizes
lex_size <- aus@entries %>%
filter(str_length(xphon_form) > 0) %>%
filter(!str_detect(tags, "duplicate|boundary_initial|boundary_final|q_mark")) %>%
group_by(lex_ID, entry_ID) %>%
slice(1) %>%
group_by(lex_ID) %>%
summarise(n_entries = n())
# Get taxon labels from Map-DB-Wordlists
# Filter to clean lex_IDs
# Attach wordlist sizes
# Filter out wordlists with < 250 entries
metadata <- read_csv("~/Desktop/Github/erichround/Ausphonlex/dbs/Map-DB-Wordlists.csv") %>%
filter(Vocab_ID %in% as.character(get_clean_lex_IDs())) %>%
filter(!is.na(Bowern_307_taxon_label)) %>%
mutate(lex_ID = as.numeric(Vocab_ID)) %>%
select(lex_ID, tip_label = Bowern_307_taxon_label) %>%
left_join(lex_size, by = "lex_ID") %>%
filter(n_entries >= 250)
write_csv(metadata, paste0("../Data/wordlist_sizes_", Sys.Date(), ".csv"))
# Get wordlist data (NB INCLUDES PRIVATE DATA)
set.seed(2020)
biphone_fwd <- as_tibble(extract_freq_dataset("biphone_fwd_clean"))
set.seed(2020)
biphone_bkwd <- as_tibble(extract_freq_dataset("biphone_bkwd_clean"))
#################
# BINARY DATASET
#################
binarize_frequencies <- function(dataset) {
dataset[, -c(1:2)][dataset[, -c(1:2)] > 0] = 1
dataset
}
phylo_data_binary <- metadata %>% left_join(biphone_fwd, by = "lex_ID") %>%
binarize_frequencies %>%
select(-lex_ID, -n_entries)
write_csv(phylo_data_binary, paste0("../data/biphone_binary_", Sys.Date(), ".csv"))
############################
# BIPHONE FREQUENCY DATASET
############################
# Forward transition probabilities and backward transition probabilities for biphones:
phylo_data_biphone_fwd <- metadata %>% left_join(biphone_fwd, by = "lex_ID") %>%
select(-lex_ID, -n_entries)
phylo_data_biphone_bkwd <- metadata %>% left_join(biphone_bkwd, by = "lex_ID") %>%
select(-lex_ID, -n_entries)
write_csv(phylo_data_biphone_fwd, paste0("../data/biphone_fwd_", Sys.Date(), ".csv"))
write_csv(phylo_data_biphone_bkwd, paste0("../data/biphone_bkwd_", Sys.Date(), ".csv"))
setwd("~/Desktop/Github/PN_treebuilding/R")
# Data wrangling
# Jayden Macklin-Cordes
# # # # # # # # # # # # #
library(tidyverse)
library(phonlex)
library(Ausphonlex)
# Load Ausphonlex
aus <- ausphonlex_v0.6.2
# Get wordlist sizes
lex_size <- aus@entries %>%
filter(str_length(xphon_form) > 0) %>%
filter(!str_detect(tags, "duplicate|boundary_initial|boundary_final|q_mark")) %>%
group_by(lex_ID, entry_ID) %>%
slice(1) %>%
group_by(lex_ID) %>%
summarise(n_entries = n())
# Get taxon labels from Map-DB-Wordlists
# Filter to clean lex_IDs
# Attach wordlist sizes
# Filter out wordlists with < 250 entries
metadata <- read_csv("~/Desktop/Github/erichround/Ausphonlex/dbs/Map-DB-Wordlists.csv") %>%
filter(Vocab_ID %in% as.character(get_clean_lex_IDs())) %>%
filter(!is.na(Bowern_307_taxon_label)) %>%
mutate(lex_ID = as.numeric(Vocab_ID)) %>%
select(lex_ID, tip_label = Bowern_307_taxon_label) %>%
left_join(lex_size, by = "lex_ID") %>%
filter(n_entries >= 250)
write_csv(metadata, paste0("../Data/wordlist_sizes_", Sys.Date(), ".csv"))
# Get wordlist data (NB INCLUDES PRIVATE DATA)
set.seed(2020)
biphone_fwd <- as_tibble(extract_freq_dataset("biphone_fwd_clean"))
set.seed(2020)
biphone_bkwd <- as_tibble(extract_freq_dataset("biphone_bkwd_clean"))
#################
# BINARY DATASET
#################
binarize_frequencies <- function(dataset) {
dataset[, -c(1:2)][dataset[, -c(1:2)] > 0] = 1
dataset
}
phylo_data_binary <- metadata %>% left_join(biphone_fwd, by = "lex_ID") %>%
binarize_frequencies %>%
select(-lex_ID, -n_entries)
write_csv(phylo_data_binary, paste0("../data/biphone_binary_", Sys.Date(), ".csv"))
############################
# BIPHONE FREQUENCY DATASET
############################
# Forward transition probabilities and backward transition probabilities for biphones:
phylo_data_biphone_fwd <- metadata %>% left_join(biphone_fwd, by = "lex_ID") %>%
select(-lex_ID, -n_entries)
phylo_data_biphone_bkwd <- metadata %>% left_join(biphone_bkwd, by = "lex_ID") %>%
select(-lex_ID, -n_entries)
write_csv(phylo_data_biphone_fwd, paste0("../data/biphone_fwd_", Sys.Date(), ".csv"))
write_csv(phylo_data_biphone_bkwd, paste0("../data/biphone_bkwd_", Sys.Date(), ".csv"))
View(metadata)
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data", "biphone_binary"))[1]
bindat <- read_csv(paste0("../Data/", datfile))
colSums(dat[,-1]) == 1
colSums(bindat[,-1]) == 1
colSums(bindat[,-1], na.rm = T) == 1
# Function to drop uninformative variables (where all values are the same)
drop_constant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- dplyr::subset(dat, select = uniquelength > 1)
df
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_uninformative_vars
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_constant_sites
# Function to drop uninformative variables (where all values are the same)
drop_constant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_constant_sites
bindat <- read_csv(paste0("../Data/", datfile))
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
uniquelength <- sapply(bindat, function(x) length(unique(x[!is.na(x)])))
length(uniquelength==112)
length(uniquelength[uniquelength==112])
length(uniquelength[uniquelength==1])
length(uniquelength[uniquelength==0])
length(colSums(bindat)[colSums(bindat) == 112])
length(colSums(bindat[,-1])[colSums(bindat[,-1]) == 112])
length(colSums(bindat[,-1], na.rm = T)[colSums(bindat[,-1], na.rm = T) == 112])
length(colSums(bindat[,-1], na.rm = T)[colSums(bindat[,-1], na.rm = T) == 0])
singletons <- colSums(bindat[,-1], na.rm = TRUE) == 1
length(singletons)
length(singletons[singletons == TRUE])
drop_singleton_sites <- function(dat) {
singletons <- colSums(dat[,-1], na.rm = TRUE) == 1 # NB assumes first col is lg names
select(dat, -names(singletons))
}
dim[bindat]
dim(bindat)
dim(drop_singleton_sites(bindat))
rop_singleton_sites(bindat)
drop_singleton_sites(bindat)
names(singletons)
select(dat, !colnames(dat) %in% names(singletons))
drop_singleton_sites <- function(dat) {
singletons <- colSums(dat[,-1], na.rm = TRUE) == 1 # NB assumes first col is lg names
select(dat, !colnames(dat) %in% names(singletons))
}
dim(drop_singleton_sites(bindat))
drop_singleton_sites <- function(dat) {
singletons <- colSums(dat[,-1], na.rm = TRUE) == 1 # NB assumes first col is lg names
select(dat, !one_of(names(singletons)))
}
dim(drop_singleton_sites(bindat))
drop_singleton_sites <- function(dat) {
singletons <- names(colSums(dat[,-1], na.rm = TRUE) == 1) # NB assumes first col is lg names
select(dat, !one_of(singletons))
}
dim(drop_singleton_sites(bindat))
dim(bindat)
singletons <- names(colSums(bindat[,-1], na.rm = TRUE) == 1)
length(singletons)
singletons <- names(colSums(bindat[,-1], na.rm = TRUE)[colSums(bindat[,-1], na.rm = TRUE) ==1])
length(singletons)
?list
# Turn dataframe into list
bindat_list <- list(bindat[,1])
bindat_list
?slice
# Turn dataframe into list
bindat_list <- lapply(bindat[,-1], 1:nrow(bindat), as.list)
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list)
names(bindat_list) <- bindat$tip_label
library(ape)
write.nexus.data(bindat_list, paste0("../Data/biphone_binary_", Sys.Date(), ".nex"), format = "standard")
?write.nexus.data
write.nexus.data(bindat_list, paste0("../Data/biphone_binary_", Sys.Date(), ".nex"), format = "standard", interleaved = FALSE, missing = "NA")
# Prepare nexus file of binary phonotactic data
# Jayden Macklin-Cordes
# # # # # # # # # # # # # # # # # # # # # # # #
library(tidyverse)
library(ape)
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data", "biphone_binary"))[1]
# Function to drop uninformative variables (where all values are missing or the same)
drop_invariant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
drop_singleton_sites <- function(dat) {
singletons <- names(colSums(dat[,-1], na.rm = TRUE)[colSums(dat[,-1], na.rm = TRUE) ==1]) # NB assumes first col is lg names
select(dat, !one_of(singletons))
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_invariant_sites %>%
drop_singleton_sites
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list)
names(bindat_list) <- bindat$tip_label
write.nexus.data(bindat_list, paste0("../Data/biphone_binary_", Sys.Date(), ".nex"), format = "standard", interleaved = FALSE, missing = "NA")
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data", "biphone_binary"))[1]
# Function to drop uninformative variables (where all values are missing or the same)
drop_invariant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
drop_singleton_sites <- function(dat) {
singletons <- names(colSums(dat[,-1], na.rm = TRUE)[colSums(dat[,-1], na.rm = TRUE) ==1]) # NB assumes first col is lg names
select(dat, !one_of(singletons))
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_invariant_sites %>%
drop_singleton_sites
bindat <- read_csv(paste0("../Data/", datfile))
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data", "biphone_binary"))[1]
# Function to drop uninformative variables (where all values are missing or the same)
drop_invariant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
drop_singleton_sites <- function(dat) {
singletons <- names(colSums(dat[,-1], na.rm = TRUE)[colSums(dat[,-1], na.rm = TRUE) ==1]) # NB assumes first col is lg names
select(dat, !one_of(singletons))
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_invariant_sites %>%
drop_singleton_sites
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list)
names(bindat_list) <- bindat$tip_label
class(bindat_list[1])
class(bindat_list[[1]])
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character)
names(bindat_list) <- bindat$tip_label
str(bindat_list)
bindat_list[bindat_list == "NA"] <- "?"
bindat_list
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(x[x == "NA"] <- "?")
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(function (x) {x[x == "NA"] <- "?"})
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(function (x) {x[x == "NA"] <- "?"})
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character)
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(function (x) {x[x=="NA"] <- "?"; x})
bindat[1:12,1:10]
# Prepare nexus file of binary phonotactic data
# Jayden Macklin-Cordes
# # # # # # # # # # # # # # # # # # # # # # # #
library(tidyverse)
library(ape)
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data", "biphone_binary"))[1]
# Function to drop uninformative variables (where all values are missing or the same)
drop_invariant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
drop_singleton_sites <- function(dat) {
singletons <- names(colSums(dat[,-1], na.rm = TRUE)[colSums(dat[,-1], na.rm = TRUE) ==1]) # NB assumes first col is lg names
select(dat, !one_of(singletons))
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_invariant_sites %>%
drop_singleton_sites
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(function (x) {x[x=="NA"] <- "?"; x})
names(bindat_list) <- bindat$tip_label
write.nexus.data(bindat_list, paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"), format = "standard", interleaved = FALSE, missing = "NA")
# Change chars in nexus file
nex <- readLines(paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
nex
?gsub
# Change chars in nexus file
nex <- readLines(paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
gsub("0123456789", "01", nex)
writeLines(nex, paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
# Change chars in nexus file
nex <- readLines(paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
nex <- gsub("0123456789", "01", nex)
writeLines(nex, paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
# Prepare nexus file of binary phonotactic data
# Jayden Macklin-Cordes
# # # # # # # # # # # # # # # # # # # # # # # #
library(tidyverse)
library(ape)
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data", "biphone_binary"))[1]
# Function to drop uninformative variables (where all values are missing or the same)
drop_invariant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
drop_singleton_sites <- function(dat) {
# NB assumes first col is lg names
singletons <- names(colSums(dat[,-1], na.rm = TRUE)[colSums(dat[,-1], na.rm = TRUE) ==1])
select(dat, !one_of(singletons))
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_invariant_sites %>%
drop_singleton_sites
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(function (x) {x[x=="NA"] <- "?"; x})
names(bindat_list) <- bindat$tip_label
write.nexus.data(bindat_list, paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"), format = "standard", interleaved = FALSE)
# Change symbols field in nexus file (ape automatically lists all 9 digits instead of just 0 and 1)
nex <- readLines(paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
nex <- gsub("0123456789", "01", nex)
writeLines(nex, paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
# Prepare nexus file of binary phonotactic data
# Jayden Macklin-Cordes
# # # # # # # # # # # # # # # # # # # # # # # #
library(tidyverse)
library(ape)
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data/csv", "biphone_binary"))[1]
# Function to drop uninformative variables (where all values are missing or the same)
drop_invariant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
drop_singleton_sites <- function(dat) {
# NB assumes first col is lg names
singletons <- names(colSums(dat[,-1], na.rm = TRUE)[colSums(dat[,-1], na.rm = TRUE) ==1])
select(dat, !one_of(singletons))
}
bindat <- read_csv(paste0("../Data/", datfile)) %>%
drop_invariant_sites %>%
drop_singleton_sites
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(function (x) {x[x=="NA"] <- "?"; x})
names(bindat_list) <- bindat$tip_label
write.nexus.data(bindat_list, paste0("../Data/nex/biphone_binary_", Sys.Date(), ".nex"), format = "standard", interleaved = FALSE)
# Change symbols field in nexus file (ape automatically lists all 9 digits instead of just 0 and 1)
nex <- readLines(paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
nex <- gsub("0123456789", "01", nex)
writeLines(nex, paste0("../Data/PN_biphone_binary_", Sys.Date(), ".nex"))
getwd()
# Prepare nexus file of binary phonotactic data
# Jayden Macklin-Cordes
# # # # # # # # # # # # # # # # # # # # # # # #
library(tidyverse)
library(ape)
# Get newest binary phonotactic dataset
datfile <- rev(list.files("../Data/csv", "biphone_binary"))[1]
# Function to drop uninformative variables (where all values are missing or the same)
drop_invariant_sites <- function(dat) {
uniquelength <- sapply(dat, function(x) length(unique(x[!is.na(x)])))
df <- subset(dat, select = uniquelength > 1)
df
}
drop_singleton_sites <- function(dat) {
# NB assumes first col is lg names
singletons <- names(colSums(dat[,-1], na.rm = TRUE)[colSums(dat[,-1], na.rm = TRUE) ==1])
select(dat, !one_of(singletons))
}
bindat <- read_csv(paste0("../Data/csv/", datfile)) %>%
drop_invariant_sites %>%
drop_singleton_sites
# Turn dataframe into list
bindat_list <- lapply(split(bindat[,-1], 1:nrow(bindat)), as.list) %>%
lapply(as.character) %>%
lapply(function (x) {x[x=="NA"] <- "?"; x})
names(bindat_list) <- bindat$tip_label
write.nexus.data(bindat_list, paste0("../Data/nex/biphone_binary_", Sys.Date(), ".nex"), format = "standard", interleaved = FALSE)
# Change symbols field in nexus file (ape automatically lists all 9 digits instead of just 0 and 1)
nex <- readLines(paste0("../Data/nex/biphone_binary_", Sys.Date(), ".nex"))
nex <- gsub("0123456789", "01", nex)
writeLines(nex, paste0("../Data/nex/biphone_binary_", Sys.Date(), ".nex"))
